
![演示](https://i-blog.csdnimg.cn/direct/39588ce8e72e47ff831ec8a190955fc1.png)

# 学习相关知识
## 什么是虚拟内存？
![虚拟内存](https://i-blog.csdnimg.cn/direct/2ab25f0071344479ae5a26aecf798f12.png)
## 什么是分页机制？
**分页机制**是计算机操作系统中用于管理内存的一种方法。它将程序的逻辑地址空间划分为固定大小的块，称为页面（Page），并将物理内存也划分为同样大小的块，称为帧（Frame）。通过这种方式，可以实现程序在物理内存中的非连续存储，从而提高内存的使用效率和程序执行的灵活性。
分页机制的**主要特点**包括：
**固定大小**：每个页面和帧都有固定的大小，通常为**4KB**或更大，这取决于具体的硬件架构。
**地址转换**：操作系统维护一个**页表(Page Table)**，用于记录每个页面到物理帧之间的映射关系。当程序访问某个逻辑地址时，CPU的内存管理单元(MMU)会根据页表将逻辑地址转换为物理地址。
**内存保护**：通过设置页表项中的权限位，可以控制对每个页面的访问权限，比如只读、可写等，从而实现内存保护。
**共享内存**：多个进程可以通过映射相同的物理帧来共享数据，提高资源利用率。
**虚拟内存支持**：分页机制是实现虚拟内存的基础，允许操作系统将不常用的页面暂时移出物理内存，存放到磁盘上的交换区或交换文件中，需要时再重新加载回内存，这样可以有效扩大可用内存空间。

## 内存和磁盘
内存（Memory）和磁盘（Disk）是计算机系统中两种非常重要的存储设备，它们各自具有不同的功能和特性，在计算机运行过程中扮演着不同的角色。

### 内存（Memory）

内存，也被称为RAM（Random Access Memory，随机存取存储器），是计算机中一种高速存储设备，用于临时存储正在运行的程序和数据。其主要特点是：

- **速度快**：内存的访问速度非常快，通常以纳秒（ns）为单位计算，使得CPU能够快速读取和写入数据。
- **易失性**：当计算机断电或者重启时，内存中的数据会丢失，因此内存主要用于临时存储。
- **成本高**：相对于其他类型的存储设备，如硬盘，内存的价格较高。
- **容量限制**：虽然现代计算机的内存容量已经相当大（如8GB、16GB甚至更多），但是相比于磁盘来说，内存的容量还是有限的。

### 磁盘（Disk）

磁盘，通常指的是硬盘驱动器（HDD, Hard Disk Drive）或固态硬盘（SSD, Solid State Drive），是一种非易失性的存储设备，用于长期存储大量的数据。磁盘的主要特点包括：

- **非易失性**：即使断电后，磁盘上存储的数据也不会丢失，适合长期保存数据。
- **大容量**：磁盘的存储容量通常很大，常见的硬盘容量从几百GB到数TB不等。
- **速度相对较慢**：与内存相比，磁盘的访问速度较慢，尤其是传统的机械硬盘（HDD），而固态硬盘（SSD）的速度要快得多，但仍然无法与内存相比。
- **成本效益**：相对于内存，磁盘的每GB成本更低，适合存储大量数据。

### 内存与磁盘的配合

在计算机系统中，内存和磁盘通常需要协同工作以达到最佳性能：

- **虚拟内存**：操作系统可以使用磁盘的一部分作为虚拟内存（也称作交换空间或页面文件），当物理内存不足时，可以将不常用的数据移到磁盘上，以释放内存空间给更需要的数据。
- **缓存机制**：为了提高数据访问速度，操作系统和应用程序经常使用内存作为缓存，预先加载可能需要的数据，减少对磁盘的频繁访问。
- **文件系统**：文件系统负责管理和组织磁盘上的数据，提供高效的文件存储和检索功能。

总之，内存和磁盘各有优势和局限，合理地利用这两种存储资源，可以使计算机系统更加高效和可靠。

## 什么是内存地址虚拟化？
内存地址虚拟化是现代操作系统中的一项关键技术，它通过引入虚拟地址空间来管理和优化内存的使用。虚拟地址空间与物理地址空间分离，使得程序可以在一个看似连续且无限大的地址空间中运行，而不需要关心实际的物理内存布局。这种机制不仅提高了内存的使用效率，还增强了系统的安全性和稳定性。

### 虚拟地址空间的基本概念

1. **虚拟地址**：这是程序直接使用的地址，它并不对应于实际的物理内存地址。每个进程都有自己独立的虚拟地址空间，这意味着不同进程之间不会相互干扰。
   
2. **物理地址**：这是实际存在于物理内存中的地址，由内存管理单元（MMU）负责管理和转换。

3. **页表**：页表是操作系统维护的一个数据结构，用于记录虚拟地址和物理地址之间的映射关系。每个进程都有自己的页表。

### 虚拟地址到物理地址的转换过程

1. **逻辑地址**：程序生成的地址，通常是虚拟地址。
2. **页表查找**：MMU 使用虚拟地址中的页号部分在页表中查找对应的物理页号。
3. **物理地址生成**：将找到的物理页号与虚拟地址中的偏移量组合起来，生成最终的物理地址。
4. **访问物理内存**：CPU 使用生成的物理地址访问实际的物理内存。

### 虚拟地址空间的优势

1. **内存隔离**：每个进程都有自己的虚拟地址空间，互不影响，提高了系统的安全性和稳定性。
2. **地址空间扩展**：虚拟地址空间可以远大于物理内存的大小，允许程序使用更大的地址空间。
3. **内存管理灵活性**：操作系统可以灵活地管理物理内存，如将不常用的页面换出到磁盘，释放物理内存给更需要的进程。
4. **内存保护**：通过页表中的权限位，可以控制对每个页面的访问权限，防止非法访问。
5. **共享内存**：多个进程可以通过映射相同的物理页来共享数据，提高资源利用率。

### 示例

假设有一个虚拟地址 `0x00007FFA00001000`，它的转换过程如下：

1. **提取页号和偏移量**：
   - 假设页大小为 4KB（即 4096 字节），则页号部分为 `0x00007FFA0000`，偏移量部分为 `0x1000`。
   
2. **查找页表**：
   - MMU 使用 `0x00007FFA0000` 在页表中查找对应的物理页号。假设查找到的物理页号为 `0x0000000010000000`。
   
3. **生成物理地址**：
   - 将物理页号 `0x0000000010000000` 和偏移量 `0x1000` 组合起来，生成物理地址 `0x0000000010001000`。
   
4. **访问物理内存**：
   - CPU 使用物理地址 `0x0000000010001000` 访问实际的物理内存。

### 多级页表

为了减少页表占用的内存空间，现代操作系统通常使用多级页表。例如，对于 64 位地址空间，可以使用四级或五级页表，每一级页表负责映射一部分地址空间，从而有效地减少页表的大小。

### 总结

内存地址虚拟化是现代操作系统中不可或缺的一部分，它通过虚拟地址空间和物理地址空间的分离，提供了内存管理的灵活性和安全性，使得程序能够在更大的地址空间中高效运行。


## 什么是多级页表？
多级页表的设计可以有效地减少页表占用的内存空间，同时提供高效的地址转换机制。
在多级页表机制中，**页目录指针表（Page Directory Pointer Table，PDP）**、**页目录表（Page Directory，PD）**和**页表（Page Table，PT）**是用于管理和转换虚拟地址到物理地址的关键数据结构。这些表的层次结构使得操作系统能够高效地管理大容量的虚拟地址空间，同时减少页表占用的内存空间。

1. 页目录指针表（PDP）
页目录指针表是多级页表的最高层，通常用于三级页表结构。每个条目指向一个页目录表。

条目数：通常有 4 个条目（每个条目占 8 字节，共 32 字节）。
条目内容：每个条目包含一个物理地址，指向一个页目录表的起始地址，以及一些标志位（如有效位、读写权限等）。
2. 页目录表（PD）
页目录表是多级页表的中间层，每个条目指向一个页表。

条目数：通常有 512 个条目（每个条目占 8 字节，共 4096 字节）。
条目内容：每个条目包含一个物理地址，指向一个页表的起始地址，以及一些标志位（如有效位、读写权限等）。
3. 页表（PT）
页表是多级页表的最低层，每个条目指向一个物理页面。

条目数：通常有 512 个条目（每个条目占 8 字节，共 4096 字节）。
条目内容：每个条目包含一个物理地址，指向一个物理页面的起始地址，以及一些标志位（如有效位、读写权限等）。

## 什么是页表项？
**PTE (Page Table Entry)** 是页表项的缩写，它是操作系统中分页机制的核心数据结构之一。PTE 存储了关于虚拟地址到物理地址映射的信息，以及页面的各种属性和状态。在现代操作系统中，PTE 通常包含以下几个部分：

**物理地址 (Physical Address)**：
这是页表项中最重要的部分，它存储了虚拟地址对应的物理地址。物理地址通常占据 PTE 的大部分位数。
**存在位 (Present Bit, PTE_V)**：
表示该页面是否存在于物理内存中。如果存在位为 1，表示页面在物理内存中；如果为 0，表示页面不在物理内存中，可能在磁盘或其他存储设备中。
**读写位 (Read/Write Bit, PTE_W)**：
表示页面是否可写。如果读写位为 1，表示页面可读写；如果为 0，表示页面只读。
**用户/超级用户位 (User/Supervisor Bit, PTE_U)**：
表示页面是否可以被用户态代码访问。如果用户/超级用户位为 1，表示页面可以被用户态代码访问；如果为 0，表示页面只能被内核态代码访问。
**脏位 (Dirty Bit, PTE_D)**：
表示页面是否被修改过。如果脏位为 1，表示页面内容已被修改；如果为 0，表示页面内容未被修改。脏位主要用于页替换算法，帮助决定哪些页面可以被换出。
**访问位 (Accessed Bit, PTE_A)**：
表示页面是否被访问过。如果访问位为 1，表示页面已被访问过；如果为 0，表示页面未被访问过。访问位也用于页替换算法，帮助决定哪些页面最近没有被访问过。
**其他位**：
根据具体架构和操作系统的需求，PTE 可能还包含其他位，如缓存控制位、执行禁用位等。

**PTE 在分页机制中的作用**
**虚拟地址到物理地址的映射**：
PTE 存储了虚拟地址到物理地址的映射关系，操作系统通过查找页表来实现虚拟地址到物理地址的转换。
**访问控制**：
通过读写位、用户/超级用户位等属性，PTE 控制对页面的访问权限，确保系统的安全性和稳定性。
**页替换算法**：
脏位和访问位用于页替换算法，帮助操作系统决定哪些页面可以被换出，以优化内存使用。
**内存保护**：
通过设置不同的访问权限，PTE 可以实现内存保护，防止非法访问和修改。
## 什么是缺页异常？
缺页异常是指CPU访问的虚拟地址时， MMU没有办法找到对应的物理地址映射关系，或者与该物理页的访问权不一致而发生的异常。

## 什么是Belady现象？
Belady现象，也称为Belady反常现象，是指在某些情况下，增加分配给一个进程的物理页面数量反而会导致更多的页面置换，从而增加页面故障的次数。这种现象最早由计算机科学家Laszlo Belady在1969年研究页面置换算法时发现。

# 代码学习
## 总控函数init
lab3\kern\init\init.c

初始化内存：使用memset将从edata到end之间的内存区域清零。
输出加载信息：通过cprintf输出内核加载的信息。
打印内核信息：调用print_kerninfo打印内核相关信息。
初始化物理内存管理：调用pmm_init初始化物理内存管理。
初始化中断描述符表：调用idt_init初始化中断描述符表。
初始化虚拟内存管理：调用vmm_init初始化虚拟内存管理。
初始化IDE设备：调用ide_init初始化IDE设备。
初始化交换分区：调用swap_init初始化交换分区。
初始化时钟中断：调用clock_init初始化时钟中断。
进入无限循环：在所有初始化完成后，进入一个无限循环，使内核保持运行状态。

grade_backtrace 相关函数
这些函数用于生成和打印调用栈信息，主要用于调试目的。具体逻辑如下：
grade_backtrace：调用grade_backtrace0，传入参数0、kern_init的地址和0xffff0000。
grade_backtrace0：调用grade_backtrace1，传入参数0、kern_init的地址和0xffff0000。
grade_backtrace1：调用grade_backtrace2，传入参数0、kern_init的地址、0xffff0000和arg1的地址。
grade_backtrace2：调用mon_backtrace，传入参数0、NULL和NULL。

lab1_print_cur_status 函数
这个函数用于记录和打印当前的状态轮次，每调用一次，round变量加1。


处理器中断控制器（**PIC**，Programmable Interrupt Controller）是硬件设备，用于**管理和调度来自外部设备的中断请求**。

中断描述符表（**IDT**，Interrupt Descriptor Table）是 x86 架构中用于存储中断向量的信息表。每个中断向量对应一个中断处理程序的入口地址和其他属性。

**IDE**（Integrated Drive Electronics）是一种早期的硬盘接口标准，后来演变为ATA（Advanced Technology Attachment）标准。IDE 接口允许计算机与硬盘、光驱等存储设备进行通信。在现代系统中，SATA（Serial ATA）接口已经取代了传统的 IDE 接口，但在某些嵌入式系统或老式系统中，IDE 接口仍然被广泛使用。
在操作系统内核中，**初始化 IDE 控制器是为了确保能够正确地与硬盘进行通信**。对于 ucore 操作系统，初始化 IDE 控制器通常包括以下几个步骤：
1.检测 IDE 控制器的存在：检查系统中是否存在 IDE 控制器。
2.检测硬盘的存在：检查连接到 IDE 控制器的硬盘是否存在。
3.配置 IDE 控制器：设置必要的寄存器，使控制器准备好接收命令。
4.初始化硬盘：设置硬盘的状态，使其准备好进行读写操作。


## 关键数据结构和相关函数分析
IDE磁盘模拟器
lab3\kern\driver\ide.c
lab3\kern\driver\ide.h

lab3\kern\fs\


## 页表项设计思路

sv39页表项（Page Table Entry）

39 位虚拟地址空间
![页表项](https://i-blog.csdnimg.cn/direct/4162ce59acbe4e7b94d0e918c62b948f.png)
![页表项](https://i-blog.csdnimg.cn/direct/cfe6f159d61042409e505c26c49b1dbf.png)

## 使用多级页表实现虚拟存储
1.初始化物理内存管理器：通过init_pmm_manager函数初始化一个物理内存管理器实例。
2.初始化内存映射：通过page_init函数检测物理内存空间，保留已使用的内存，并创建自由页面列表。
3.分配和释放页面：通过alloc_pages和free_pages函数分配和释放连续的物理页面。
4.设置和启用分页机制：通过boot_map_segment和enable_paging函数设置和启用分页机制。
5.检查内存管理的正确性：通过check_alloc_page、check_pgdir和check_boot_pgdir函数验证内存管理的正确性。
6.动态内存分配和释放：通过kmalloc和kfree函数实现动态内存分配和释放。







# 练习与挑战
## 练习0：填写已有实验
本实验依赖实验1/2。请把你做的实验1/2的代码填入本实验中代码中有“LAB1”,“LAB2”的注释相应部分。

## 练习1：理解基于FIFO的页面替换算法（思考题）
描述FIFO页面置换算法下，一个页面从被换入到被换出的过程中，会经过代码里哪些函数/宏的处理（或者说，需要调用哪些函数/宏），并用简单的一两句话描述每个函数在过程中做了什么？（为了方便同学们完成练习，所以实际上我们的项目代码和实验指导的还是略有不同，例如我们将FIFO页面置换算法头文件的大部分代码放在了`kern/mm/swap_fifo.c`文件中，这点请同学们注意）
 - 至少正确指出10个不同的函数分别做了什么？如果少于10个将酌情给分。我们认为只要函数原型不同，就算两个不同的函数。要求指出对执行过程有实际影响,删去后会导致输出结果不同的函数（例如assert）而不是cprintf这样的函数。如果你选择的函数不能完整地体现”从换入到换出“的过程，比如10个函数都是页面换入的时候调用的，或者解释功能的时候只解释了这10个函数在页面换入时的功能，那么也会扣除一定的分数
### 页面换入过程

1. **_fifo_init_mm**
   - **作用**：初始化页面置换队列 `pra_list_head`，并将 `mm->sm_priv` 指向该队列的地址。
   - **调用时机**：在进程的内存管理结构初始化时调用。
   - **代码位置**：`kern/mm/swap_fifo.c`

2. **list_init**
   - **作用**：初始化链表，确保链表为空。
   - **调用时机**：在 `_fifo_init_mm` 中初始化 `pra_list_head` 时调用。
   - **代码位置**：`libs/list.h`

3. **_fifo_map_swappable**
   - **作用**：将新换入的页面链接到 `pra_list_head` 的末尾，记录页面的换入时间。
   - **调用时机**：在页面被映射为可交换时调用。
   - **代码位置**：`kern/mm/swap_fifo.c`

4. **list_add**
   - **作用**：将新节点添加到链表的末尾，保持页面的顺序。
   - **调用时机**：在 `_fifo_map_swappable` 中将新页面添加到 `pra_list_head` 的末尾时调用。
   - **代码位置**：`libs/list.h`

5. **le2page**
   - **作用**：将链表节点转换为页面结构体指针，以便后续操作。
   - **调用时机**：在 `_fifo_swap_out_victim` 中将链表节点转换为页面结构体指针。
   - **代码位置**：`memlayout.h`

### 页面换出过程

6. **_fifo_swap_out_victim**
   - **作用**：从 `pra_list_head` 的头部选择最早到达的页面作为替换对象，并将其从链表中删除。
   - **调用时机**：在需要替换页面时调用。
   - **代码位置**：`kern/mm/swap_fifo.c`

7. **list_prev**
   - **作用**：返回指定节点的前一个节点，用于找到链表的最后一个节点。
   - **调用时机**：在 `_fifo_swap_out_victim` 中找到 `pra_list_head` 的最后一个节点时调用。
   - **代码位置**：`libs/list.h`

8. **list_del**
   - **作用**：从链表中删除指定节点，释放页面。
   - **调用时机**：在 `_fifo_swap_out_victim` 中删除最早到达的页面节点时调用。
   - **代码位置**：`libs/list.h`

### 辅助函数

9. **_fifo_check_swap**
   - **作用**：测试页面置换算法的正确性，通过访问虚拟地址来触发页面置换。
   - **调用时机**：在测试页面置换算法时调用。
   - **代码位置**：`kern/mm/swap_fifo.c`

10. **assert**
    - **作用**：断言检查，确保某些条件成立，否则程序会终止。
    - **调用时机**：在 `_fifo_check_swap` 和其他函数中进行条件检查。


## 练习2：深入理解不同分页模式的工作原理（思考题）
get_pte()函数（位于`kern/mm/pmm.c`）用于在页表中查找或创建页表项，从而实现对指定线性地址对应的物理页的访问和映射操作。这在操作系统中的分页机制下，是实现虚拟内存与物理内存之间映射关系非常重要的内容。
 - get_pte()函数中有两段形式类似的代码， 结合sv32，sv39，sv48的异同，解释这两段代码为什么如此相像。
 - 目前get_pte()函数将页表项的查找和页表项的分配合并在一个函数里，你认为这种写法好吗？有没有必要把两个功能拆开？
### 1. `get_pte()`函数中有两段形式类似的代码，结合sv32，sv39，sv48的异同，解释这两段代码为什么如此相像。

`get_pte()`函数在不同的分页模式下（如sv32、sv39、sv48）中查找或创建页表项。尽管这些分页模式有不同的层次和地址空间大小，它们的基本工作原理是相似的。因此，`get_pte()`函数在这几种模式下的实现代码形式相似，主要体现在以下几个方面：

1. **层次结构**：
   - **sv32**：使用两级页表，每个页表项占用32位。
   - **sv39**：使用三级页表，每个页表项占用39位。
   - **sv48**：使用四级页表，每个页表项占用48位。

2. **地址分解**：
   - 在所有这些模式下，虚拟地址都被分解成多个部分，用于索引各级页表。
   - 例如，在sv39模式下，虚拟地址被分解为：
     - 39位虚拟地址：`VPN[2][1][0] | OFFSET`
     - 其中，`VPN[2]`、`VPN[1]`、`VPN[0]`分别用于索引三级页表，`OFFSET`用于索引物理页面内的偏移。

3. **查找和创建页表项**：
   - 在每种模式下，都需要逐级查找页表项，如果某一级页表项不存在，则需要创建新的页表。
   - 这个过程在所有模式下都是相似的，只是层级数量不同。

因此，`get_pte()`函数在这几种模式下的实现代码形式相似，因为它们都遵循相同的逻辑：逐级查找和创建页表项。

### 2. 目前`get_pte()`函数将页表项的查找和页表项的分配合并在一个函数里，你认为这种写法好吗？有没有必要把两个功能拆开？

#### 优点

1. **简洁性**：
   - 将查找和分配合并在一个函数中，代码更加简洁，减少了函数调用的开销。
   - 对于大多数使用场景，这种合并的方式已经足够高效和方便。

2. **一致性**：
   - 查找和分配操作通常是一起进行的，合并在一起可以确保操作的一致性和原子性。

#### 缺点

1. **灵活性**：
   - 如果某些情况下只需要查找而不分配，或者只需要分配而不查找，这种合并的方式可能会显得不够灵活。
   - 例如，某些高级内存管理策略可能需要单独的查找和分配操作。

2. **可测试性**：
   - 单独的查找和分配函数更容易进行单元测试，可以更精细地测试每个功能。

#### 是否有必要拆开

- **不需要拆开的情况**：
  - 如果当前的实现已经满足了系统的需求，并且没有明显的性能瓶颈或功能需求上的限制，那么保持现有的实现是合理的。
  - 大多数操作系统内核中，`get_pte()`函数通常就是这样实现的，因为这样可以简化代码逻辑并提高效率。

- **需要拆开的情况**：
  - 如果未来需要实现更复杂的内存管理策略，或者需要更细粒度的控制和测试，可以考虑将查找和分配功能拆分开来。
  - 拆分后，可以提供更多的灵活性，但也会增加代码的复杂性和维护成本。

### 总结

目前`get_pte()`函数将页表项的查找和分配合并在一起的做法是合理的，因为它简洁且高效。除非有明确的需求需要更细粒度的控制或测试，否则没有必要将这两个功能拆开。

## 练习3：给未被映射的地址映射上物理页（需要编程）
补充完成do_pgfault（mm/vmm.c）函数，给未被映射的地址映射上物理页。设置访问权限 的时候需要参考页面所在 VMA 的权限，同时需要注意映射物理页时需要操作内存控制 结构所指定的页表，而不是内核的页表。
请在实验报告中简要说明你的设计实现过程。请回答如下问题：
 - 请描述页目录项（Page Directory Entry）和页表项（Page Table Entry）中组成部分对ucore实现页替换算法的潜在用处。
 - 如果ucore的缺页服务例程在执行过程中访问内存，出现了页访问异常，请问硬件要做哪些事情？
- 数据结构Page的全局变量（其实是一个数组）的每一项与页表中的页目录项和页表项有无对应关系？如果有，其对应关系是啥？
### 设计实现过程

1. **查找 VMA**：
   - 使用 `find_vma` 函数查找包含 `addr` 的虚拟内存区域（VMA）。如果找不到合适的 VMA 或者 `addr` 超出了 VMA 的范围，则返回错误。

2. **设置权限**：
   - 根据 VMA 的权限设置页面的访问权限。如果 VMA 允许写操作，则设置读写权限；否则仅设置读权限。

3. **映射物理页**：
   - 使用 `get_pte` 函数获取或创建页表项（PTE）。如果 PTE 为空，分配一个新的物理页并使用 `page_insert` 函数将其映射到虚拟地址。
   - 如果 PTE 非空且页面在交换空间中，使用 `swap_in` 函数从交换空间加载页面内容到内存中，然后使用 `page_insert` 函数建立映射，并使用 `swap_map_swappable` 函数设置页面可交换。

### 问题
1. **页目录项（Page Directory Entry）和页表项（Page Table Entry）中组成部分对 ucore 实现页替换算法的潜在用处**：
   - **页目录项（PDE）**：
     - **存在位（Present Bit）**：用于标识对应的页表是否存在于物理内存中。如果不存在，可能需要从磁盘加载页表。
     - **读写位（Read/Write Bit）**：用于标识页面是否可读写。
     - **用户/超级用户位（User/Supervisor Bit）**：用于标识页面是否可以被用户态代码访问。
     - **脏位（Dirty Bit）**：用于标识页面是否被修改过，对于页替换算法有用，可以帮助确定哪些页面可以被换出。
     - **访问位（Accessed Bit）**：用于标识页面是否被访问过，对于页替换算法有用，可以帮助确定哪些页面最近没有被访问过。
   - **页表项（PTE）**：
     - **存在位（Present Bit）**：用于标识对应的页面是否存在于物理内存中。如果不存在，可能需要从磁盘加载页面。
     - **读写位（Read/Write Bit）**：用于标识页面是否可读写。
     - **用户/超级用户位（User/Supervisor Bit）**：用于标识页面是否可以被用户态代码访问。
     - **脏位（Dirty Bit）**：用于标识页面是否被修改过，对于页替换算法有用，可以帮助确定哪些页面可以被换出。
     - **访问位（Accessed Bit）**：用于标识页面是否被访问过，对于页替换算法有用，可以帮助确定哪些页面最近没有被访问过。

2. **如果 ucore 的缺页服务例程在执行过程中访问内存，出现了页访问异常，硬件要做哪些事情**：
   - **中断处理**：硬件会生成一个中断，将控制权交给操作系统。
   - **保存状态**：硬件会保存当前的处理器状态，包括程序计数器（PC）、寄存器状态等。
   - **传递错误码**：硬件会将错误码传递给操作系统，错误码包含了导致页故障的原因（如不存在、访问权限不足等）。
   - **传递故障地址**：硬件会将引起页故障的虚拟地址传递给操作系统，通常通过控制寄存器（如 CR2）。
   - **中断向量表**：硬件会根据中断类型跳转到相应的中断处理程序（如页故障处理程序）。

3. **数据结构 Page 的全局变量（其实是一个数组）的每一项与页表中的页目录项和页表项有无对应关系？如果有，其对应关系是啥**：
   - **对应关系**：
     - **Page 结构**：每个 `Page` 结构表示一个物理页面，包含页面的各种属性和状态信息。
     - **页表项（PTE）**：每个 PTE 包含一个物理页面的地址和其他属性（如存在位、读写位等）。
     - **对应关系**：每个 `Page` 结构可以通过其物理地址与页表项中的物理地址字段对应。具体来说，`Page` 结构中的物理地址可以通过 `page2pa` 函数转换为物理地址，而页表项中的物理地址可以通过 `PTE_ADDR` 宏提取出来。两者通过物理地址建立对应关系。

## 练习4：补充完成Clock页替换算法（需要编程）
通过之前的练习，相信大家对FIFO的页面替换算法有了更深入的了解，现在请在我们给出的框架上，填写代码，实现 Clock页替换算法（mm/swap_clock.c）。
请在实验报告中简要说明你的设计实现过程。请回答如下问题：
 - 比较Clock页替换算法和FIFO算法的不同。

### 设计

Clock 页面替换算法是一种改进的页面替换算法，它通过引入一个“指针”来模拟时钟的指针移动，从而避免了 FIFO 算法中的 Belady 异常问题。下面是如何实现 Clock 页面替换算法的详细步骤：

1. **初始化**：
   - 初始化页面链表 `pra_list_head`。
   - 初始化当前指针 `curr_ptr` 指向页面链表的头部。
   - 将 `mm->sm_priv` 指向页面链表的头部。

2. **映射可交换页面**：
   - 将新页面插入到页面链表的末尾。
   - 将页面的 `visited` 标志置为 1，表示该页面已被访问。

3. **选择换出页面**：
   - 从当前指针位置开始遍历页面链表，寻找一个 `visited` 标志为 0 的页面。
   - 如果找到这样的页面，将其从链表中删除，并返回该页面。
   - 如果所有页面的 `visited` 标志都为 1，将所有页面的 `visited` 标志重置为 0，继续查找。

### 设计实现过程

1. **初始化**：
   - 在 `_clock_init_mm` 函数中，初始化页面链表 `pra_list_head` 并将其地址赋值给 `mm->sm_priv`，同时初始化当前指针 `curr_ptr` 指向链表头部。

2. **映射可交换页面**：
   - 在 `_clock_map_swappable` 函数中，将新页面插入到页面链表的末尾，并将页面的 `visited` 标志置为 1。

3. **选择换出页面**：
   - 在 `_clock_swap_out_victim` 函数中，从当前指针位置开始遍历页面链表，寻找一个 `visited` 标志为 0 的页面。如果找到这样的页面，将其从链表中删除并返回该页面。如果所有页面的 `visited` 标志都为 1，将所有页面的 `visited` 标志重置为 0，继续查找。

### 比较 Clock 页替换算法和 FIFO 算法的不同

1. **页面选择策略**：
   - **FIFO**：总是选择最早进入内存的页面进行替换，容易导致 Belady 异常。
   - **Clock**：使用一个指针模拟时钟指针，遍历页面链表，选择一个未被访问的页面进行替换。如果所有页面都被访问过，则重置访问标志并继续查找。

2. **性能**：
   - **FIFO**：简单但性能较差，容易导致频繁的页面替换。
   - **Clock**：通过重置访问标志，避免了频繁的页面替换，提高了内存利用率。

3. **实现复杂度**：
   - **FIFO**：实现简单，只需维护一个队列。
   - **Clock**：实现稍复杂，需要维护一个指针和访问标志。

通过这些改进，Clock 页面替换算法在实际应用中表现更好，能够有效地减少页面替换的频率，提高系统的整体性能。


## 练习5：阅读代码和实现手册，理解页表映射方式相关知识（思考题）
如果我们采用”一个大页“ 的页表映射方式，相比分级页表，有什么好处、优势，有什么坏处、风险？

### 什么是“一个大页”的页表映射方式？

“一个大页”的页表映射方式是指使用较大的页面大小（例如 2MB 或 1GB）来映射虚拟地址到物理地址，而不是传统的 4KB 小页面。这种方式在某些情况下可以提高内存管理和访问的效率。

### 好处和优势

1. **减少页表项数量**：
   - 使用大页面可以显著减少页表项的数量。例如，使用 2MB 的大页面，一个 4GB 的地址空间只需要 2048 个页表项，而使用 4KB 的小页面则需要 1048576 个页表项。
   - 减少页表项数量可以降低页表占用的内存空间，减少页表查找的时间开销。

2. **提高 TLB 命中率**：
   - TLB（Translation Lookaside Buffer）是 CPU 中的一个高速缓存，用于存储最近使用的页表项。使用大页面可以减少 TLB 的条目数量，从而提高 TLB 的命中率，减少 TLB 缺失带来的性能损失。

3. **减少页表管理开销**：
   - 由于页表项数量减少，页表的管理和维护开销也会降低。例如，分配和回收页面的操作会变得更简单和高效。

4. **减少内存碎片**：
   - 使用大页面可以减少内存碎片，特别是在处理大量连续内存区域时。这对于某些需要大量连续内存的应用（如图形处理、大数据处理等）特别有用。

### 坏处和风险

1. **内存浪费**：
   - 使用大页面可能会导致内存浪费。如果一个大页面中只有少量的数据被使用，剩余的空间将无法被其他进程或数据使用，从而造成内存浪费。
   - 例如，一个 2MB 的大页面中只有 100KB 的数据被使用，剩下的 1.9MB 空间将无法被利用。

2. **灵活性降低**：
   - 大页面的分配和释放不如小页面灵活。对于需要动态分配和释放小块内存的应用，使用大页面可能会增加内存管理的复杂度。
   - 特别是在内存紧张的情况下，大页面的分配可能会失败，而小页面则更容易分配成功。

3. **内存碎片问题**：
   - 虽然大页面可以减少内存碎片，但在某些情况下，大页面的分配和释放可能会导致更大的内存碎片问题。例如，如果多个大页面被分配和释放，可能会导致内存布局变得不规则，影响内存的高效使用。

4. **兼容性问题**：
   - 不是所有的硬件和操作系统都支持大页面。在一些老的或特定的硬件平台上，可能无法使用大页面。
   - 此外，某些应用程序可能依赖于小页面的行为，使用大页面可能会导致兼容性问题。

### 应用场景

1. **高性能计算**：
   - 在高性能计算和科学计算中，使用大页面可以显著提高内存访问速度，减少 TLB 缺失，从而提升整体性能。

2. **图形处理**：
   - 图形处理通常需要大量的连续内存，使用大页面可以减少内存碎片，提高内存管理的效率。

3. **数据库和大数据处理**：
   - 数据库和大数据处理应用通常需要处理大量的数据，使用大页面可以减少页表项数量，提高内存访问速度。

4. **虚拟化**：
   - 在虚拟化环境中，使用大页面可以减少虚拟机之间的内存干扰，提高虚拟机的性能。
### 总结

“一个大页”的页表映射方式在某些应用场景下具有明显的优势，如减少页表项数量、提高 TLB 命中率、减少内存碎片等。然而，它也有潜在的缺点，如内存浪费、灵活性降低、内存碎片问题和兼容性问题。因此，在选择是否使用大页面时，需要根据具体的系统需求和应用场景进行权衡。

## 扩展练习 Challenge：实现不考虑实现开销和效率的LRU页替换算法（需要编程）
challenge部分不是必做部分，不过在正确最后会酌情加分。需写出有详细的设计、分析和测试的实验报告。完成出色的可获得适当加分。

### LRU（Least Recently Used）页替换算法

LRU（Least Recently Used）页替换算法是一种常用的页面替换算法，它的基本思想是选择最近最少使用的页面进行替换。LRU 算法基于这样一个假设：最近很少使用的页面在未来一段时间内也很少会被使用。因此，通过替换这些页面，可以最大限度地减少页面替换的频率，提高内存的使用效率。

#### 工作原理

1. **记录页面访问情况**：
   - 每当一个页面被访问时，记录该页面的访问时间或访问次数。
   - 可以使用一个时间戳或一个计数器来记录每个页面的访问情况。

2. **选择替换页面**：
   - 当需要替换页面时，选择最近最少使用的页面进行替换。
   - 通过比较各个页面的访问时间或访问次数，选择最旧的页面进行替换。

#### 优点

1. **高效率**：
   - LRU 算法通常能够有效地减少页面替换的频率，提高系统的整体性能。
   - 通过选择最近最少使用的页面进行替换，可以最大限度地保留经常使用的页面，减少页面缺失的次数。

2. **适应性强**：
   - LRU 算法能够很好地适应各种工作负载，特别是那些访问模式较为固定的工作负载。
   - 对于具有局部性特征的应用程序（即一段时间内访问的页面相对集中），LRU 算法表现尤为出色。

3. **减少内存碎片**：
   - 通过选择最近最少使用的页面进行替换，可以更好地管理内存，减少内存碎片。

#### 缺点

1. **实现复杂度**：
   - LRU 算法的实现相对复杂，需要维护每个页面的访问时间或访问次数。
   - 需要额外的内存来存储这些信息，增加了系统的开销。

2. **性能开销**：
   - 每次页面访问都需要更新访问记录，增加了系统的性能开销。
   - 选择替换页面时需要进行大量的比较操作，也可能影响性能。

3. **近似实现**：
   - 完全精确的 LRU 算法在实际应用中很难实现，通常需要使用近似的实现方法。
   - 例如，可以使用一个栈或队列来近似记录页面的访问顺序，但这可能会引入一定的误差。

#### 近似实现方法

1. **栈算法（Stack Algorithm）**：
   - 使用一个栈来记录页面的访问顺序。每当一个页面被访问时，将其移到栈顶。
   - 当需要替换页面时，选择栈底的页面进行替换。

2. **队列算法（Queue Algorithm）**：
   - 使用一个队列来记录页面的访问顺序。每当一个页面被访问时，将其移到队列尾部。
   - 当需要替换页面时，选择队列头部的页面进行替换。

3. **计数器算法（Counter Algorithm）**：
   - 使用一个计数器来记录每个页面的访问次数。每当一个页面被访问时，增加其计数器值。
   - 当需要替换页面时，选择计数器值最小的页面进行替换。

#### 代码

以下是一个简单的 LRU 页面替换算法的实现示例：

```c
#include <defs.h>
#include <riscv.h>
#include <stdio.h>
#include <string.h>
#include <swap.h>
#include <swap_lru.h>
#include <list.h>

list_entry_t lru_list_head;
list_entry_t *lru_curr_ptr;

// 初始化 LRU 页面替换算法
static int
_lru_init_mm(struct mm_struct *mm)
{
    list_init(&lru_list_head);
    lru_curr_ptr = &lru_list_head;
    mm->sm_priv = &lru_list_head;
    return 0;
}

// 映射可交换页面
static int
_lru_map_swappable(struct mm_struct *mm, uintptr_t addr, struct Page *page, int swap_in)
{
    list_entry_t *entry = &(page->lru_page_link);
    assert(entry != NULL && lru_curr_ptr != NULL);

    // 将页面插入到 LRU 链表的末尾
    list_add_before(lru_curr_ptr, entry);

    // 将当前指针移到新插入的页面
    lru_curr_ptr = entry;

    return 0;
}

// 选择换出页面
static int
_lru_swap_out_victim(struct mm_struct *mm, struct Page **ptr_page, int in_tick)
{
    list_entry_t *head = (list_entry_t *)mm->sm_priv;
    assert(head != NULL);
    assert(in_tick == 0);

    // 从链表头部开始查找最近最少使用的页面
    list_entry_t *entry = head->next;
    while (entry != head) {
        struct Page *page = le2page(entry, lru_page_link);
        *ptr_page = page;
        list_del(entry);  // 删除页面链表中的条目
        return 0;
    }

    return -E_INVAL;
}

// 检查页面替换算法
static int
_lru_check_swap(void)
{
#ifdef ucore_test
    int score = 0, totalscore = 5;
    cprintf("%d\n", &score);
    ++score; cprintf("grading %d/%d points", score, totalscore);
    *(unsigned char *)0x3000 = 0x0c;
    assert(pgfault_num == 4);
    *(unsigned char *)0x1000 = 0x0a;
    assert(pgfault_num == 4);
    *(unsigned char *)0x4000 = 0x0d;
    assert(pgfault_num == 4);
    *(unsigned char *)0x2000 = 0x0b;
    ++score; cprintf("grading %d/%d points", score, totalscore);
    assert(pgfault_num == 4);
    *(unsigned char *)0x5000 = 0x0e;
    assert(pgfault_num == 5);
    *(unsigned char *)0x2000 = 0x0b;
    assert(pgfault_num == 5);
    ++score; cprintf("grading %d/%d points", score, totalscore);
    *(unsigned char *)0x1000 = 0x0a;
    assert(pgfault_num == 5);
    *(unsigned char *)0x2000 = 0x0b;
    assert(pgfault_num == 5);
    *(unsigned char *)0x3000 = 0x0c;
    assert(pgfault_num == 5);
    ++score; cprintf("grading %d/%d points", score, totalscore);
    *(unsigned char *)0x4000 = 0x0d;
    assert(pgfault_num == 5);
    *(unsigned char *)0x5000 = 0x0e;
    assert(pgfault_num == 5);
    assert(*(unsigned char *)0x1000 == 0x0a);
    *(unsigned char *)0x1000 = 0x0a;
    assert(pgfault_num == 6);
    ++score; cprintf("grading %d/%d points", score, totalscore);
#else
    *(unsigned char *)0x3000 = 0x0c;
    assert(pgfault_num == 4);
    *(unsigned char *)0x1000 = 0x0a;
    assert(pgfault_num == 4);
    *(unsigned char *)0x4000 = 0x0d;
    assert(pgfault_num == 4);
    *(unsigned char *)0x2000 = 0x0b;
    assert(pgfault_num == 4);
    *(unsigned char *)0x5000 = 0x0e;
    assert(pgfault_num == 5);
    *(unsigned char *)0x2000 = 0x0b;
    assert(pgfault_num == 5);
    *(unsigned char *)0x1000 = 0x0a;
    assert(pgfault_num == 5);
    *(unsigned char *)0x2000 = 0x0b;
    assert(pgfault_num == 5);
    *(unsigned char *)0x3000 = 0x0c;
    assert(pgfault_num == 5);
    *(unsigned char *)0x4000 = 0x0d;
    assert(pgfault_num == 5);
    *(unsigned char *)0x5000 = 0x0e;
    assert(pgfault_num == 5);
    assert(*(unsigned char *)0x1000 == 0x0a);
    *(unsigned char *)0x1000 = 0x0a;
    assert(pgfault_num == 6);
#endif
    return 0;
}

static int
_lru_init(void)
{
    return 0;
}

static int
_lru_set_unswappable(struct mm_struct *mm, uintptr_t addr)
{
    return 0;
}

static int
_lru_tick_event(struct mm_struct *mm)
{
    return 0;
}

struct swap_manager swap_manager_lru =
{
    .name            = "lru swap manager",
    .init            = &_lru_init,
    .init_mm         = &_lru_init_mm,
    .tick_event      = &_lru_tick_event,
    .map_swappable   = &_lru_map_swappable,
    .set_unswappable = &_lru_set_unswappable,
    .swap_out_victim = &_lru_swap_out_victim,
    .check_swap      = &_lru_check_swap,
};
```

### 实验报告

#### 设计实现过程

1. **初始化**：
   - 在 `_lru_init_mm` 函数中，初始化 LRU 页面链表 `lru_list_head` 并将其地址赋值给 `mm->sm_priv`，同时初始化当前指针 `lru_curr_ptr` 指向链表头部。

2. **映射可交换页面**：
   - 在 `_lru_map_swappable` 函数中，将新页面插入到 LRU 链表的末尾，并将当前指针移到新插入的页面。

3. **选择换出页面**：
   - 在 `_lru_swap_out_victim` 函数中，从链表头部开始查找最近最少使用的页面。找到后，将其从链表中删除并返回该页面。

#### 好处和优势

1. **高效率**：
   - LRU 算法能够有效地减少页面替换的频率，提高系统的整体性能。
   - 通过选择最近最少使用的页面进行替换，可以最大限度地保留经常使用的页面，减少页面缺失的次数。

2. **适应性强**：
   - LRU 算法能够很好地适应各种工作负载，特别是那些访问模式较为固定的工作负载。
   - 对于具有局部性特征的应用程序，LRU 算法表现尤为出色。

3. **减少内存碎片**：
   - 通过选择最近最少使用的页面进行替换，可以更好地管理内存，减少内存碎片。

#### 坏处和风险

1. **实现复杂度**：
   - LRU 算法的实现相对复杂，需要维护每个页面的访问时间或访问次数。
   - 需要额外的内存来存储这些信息，增加了系统的开销。

2. **性能开销**：
   - 每次页面访问都需要更新访问记录，增加了系统的性能开销。
   - 选择替换页面时需要进行大量的比较操作，也可能影响性能。

3. **近似实现**：
   - 完全精确的 LRU 算法在实际应用中很难实现，通常需要使用近似的实现方法。
   - 例如，可以使用一个栈或队列来近似记录页面的访问顺序，但这可能会引入一定的误差。

通过这些改进，LRU 页面替换算法在实际应用中表现良好，能够有效地提高内存管理和访问的效率。


# 遇到的问题
![error](https://i-blog.csdnimg.cn/direct/2c72abfe579d4564afe9ef787b6831ad.png)

**multiple definition of `pra_list_head'**

在 swap_clock.c 中定义 pra_list_head：
```
list_entry_t pra_list_head;
list_entry_t *curr_ptr;
```
在 swap_fifo.c 文件中，声明 pra_list_head 为外部变量：
```
extern list_entry_t pra_list_head;
extern list_entry_t *curr_ptr;
```

